[{"content":"安装hugo Hugo官网： The world’s fastest framework for building websites\n下载下面这个即可：\n将压缩包解压到 bin 目录下：\n配置环境变量 配置环境变量，就可以在任意位置使用hugo命令了\n任意位置打开cmd，输入hugo version验证一下\n搭建博客 创建博客 在任意位置打开cmd，输入：hugo new site xxx\n可以看到对应位置出现文件夹\ncd进入对应的目录，然后使用命令启动hugo\n1 2 3 4 5 hugo server --buildDrafts # 或者简写 hugo server -D # 或者 hugo server 在浏览器输入 http://localhost:1313，出现Page Not Found则表示成功，Page Not Found是因为还没配主题\n配置主题 在hugo官网找一个喜欢的主题下载即可\n选择主题的源码并下载\n解压并放到themes目录下\n打开exampleSite文件夹，将 Content 和 hugo.yaml 复制到主文件夹下\n修改theme为themes文件夹下的主题名，以后需要换一个主题也是修改这里\n重新启动hugo即可，相关配置修改**hugo.yaml**\nstack官网：\nStack | Card-style Hugo theme designed for bloggers (jimmycai.com)\n写博客 在指定位置打开cmd 创建index.md 1 hugo new content post/MyFirstBlog/index.md 其中/MyFirstBlog可以任意命名\n/index.md 不能任意命名，否则图片等资源无法显示\n最后，就可以愉快的在index.md中写博客了\n","date":"2024-09-25T21:27:40+08:00","image":"https://gcore.jsdelivr.net/gh/XXL999227/image/img/20241010210254.png","permalink":"https://xxl999227.github.io/archives/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","title":"HUGO搭建博客"},{"content":"1、服务调用出现的问题 :::color3\n服务消费者该如何获取服务提供者的地址信息？ 果有多个服务提供者，消费者该如何选择？ 消费者如何得知服务提供者的健康状态？ :::\n2、Eureka的作用 消费者该如何获取服务提供者具体信息？\n服务提供者启动时向eureka注册自己的信息\neureka保存这些信息\n消费者根据服务名称向eureka拉取提供者信息\n如果有多个服务提供者，消费者该如何选择？\n服务消费者利用负载均衡算法，从服务列表中挑选一个\n消费者如何感知服务提供者健康状态？\n服务提供者会每隔30秒向EurekaServer发送心跳请求，报告健康状态\neureka会更新记录服务列表信息，心跳不正常会被剔除\n消费者就可以拉取到最新的信息\n3、总结 ","date":"2024-04-16T16:23:35+08:00","permalink":"https://xxl999227.github.io/archives/%E5%BE%AE%E6%9C%8D%E5%8A%A13eureka%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/","title":"【微服务】3、Eureka注册中心"},{"content":"1、微服务拆分 cloud-order.sqlcloud-user.sql\n2、提供者与消费者 :::warning\n服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务） 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口） :::\n服务调用关系\n:::color2\n服务提供者：暴露接口给其它微服务调用 服务消费者：调用其它微服务提供的接口 提供者与消费者角色其实是相对的 一个服务可以同时是服务提供者和服务消费者 :::\n","date":"2024-04-16T15:33:50+08:00","permalink":"https://xxl999227.github.io/archives/%E5%BE%AE%E6%9C%8D%E5%8A%A12%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%E5%8F%8A%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8/","title":"【微服务】2、服务拆分及远程调用"},{"content":"1、服务架构演变 微服务是一种经过良好架构设计的分布式架构方案，微服务架构特征：\n单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责，避免重复业务开发 面向服务：微服务对外暴露业务接口 自治：团队独立、技术独立、数据独立、部署独立 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题 2、微服务技术对比 3、SpringCloud SpringCloud是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。 SpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验： lSpringCloud与SpringBoot的版本兼容关系可以在官网找到 ：\n我们用的版本是 Hoxton.SR10，因此对应的SpringBoot版本是2.3.x版本。\n","date":"2024-04-16T15:24:26+08:00","permalink":"https://xxl999227.github.io/archives/%E5%BE%AE%E6%9C%8D%E5%8A%A11%E8%AE%A4%E8%AF%86%E5%BE%AE%E6%9C%8D%E5%8A%A1/","title":"【微服务】1、认识微服务"},{"content":"第一章：Kubernetes 集群架构 Docker 是每一个节点（包括 Master 节点和 Node 节点）的运行时环境（也有Containerd）。 kubelet 负责控制所有容器的启动和停止等，保证每个节点（包括 Master 节点和 Node 节点）正常工作，并且帮助 Node 节点和 Master 节点进行交互。 Master 节点的关键组件： kubelet（监工）：所有节点必备的。控制当前节点所有 Pod 的生命周期以及与 api-server 交互等工作。 kube-api-server：负责接收所有请求。集群内对集群的任何修改都是通过命令行、UI 将请求发给 api-server 才能执行的。api-server 是整个集群操作对内、对外的唯一入口，不包含我们后来部署应用暴露端口的方式。 kube-proxy：整个节点的网络流量负责。 cri：容器运行时环境（如：Docker 、Podman 等）。 …… Node 节点的关键组件： kubelet（监工）：所有节点必备的。控制当前节点所有 Pod 的生命周期以及与 api-server 交互等工作。 kube-proxy：整个节点的网络流量负责。 cri：容器运行时环境（如：Docker 、Podman 等）。 第二章：资源管理方式 概述 ① 命令式对象管理：直接通过命令去操作 Kubernetes 的资源。 1 kubectl run nginx-pod --image=nginx:1.17.1 --port=80 ② 命令式对象配置：通过命令配置和配置文件去操作 Kubernetes 的资源。 1 kubectl create/patch/delete -f nginx-pod.yaml ③ 声明式对象配置：通过 apply 命令和配置文件去操作 Kubernetes 的资源。 1 kubectl apply -f nginx-pod.yaml 总结： 类型 操作 适用场景 优点 缺点 命令式对象管理 对象 测试 简单 只能操作活动对象，无法审计、跟踪 命令式对象配置 文件 开发 可以审计、跟踪 项目大的时候，配置文件多，操作麻烦 声明式对象配置 目录 开发 支持目录操作 意外情况下难以调试 命令式对象管理 kubectl 命令 kubectl 是 Kubernetes 集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装和部署。 kubectl 命令的语法如下： 1 kubectl [command] [type] [name] [flags] 参数： command：指定要对资源执行的操作，如：create、get 、delete 等。 type：指定资源的类型，如：deployment 、pod 、service 等。 name：指定资源的名称，名称大小写敏感。 flags：指定额外的可选参数。 示例：查看所有的 Pod 1 kubectl get pod 示例：以 yaml 格式查看某个 Pod 1 kubectl get pod 《pod_name》 -o yaml 操作（command） Kubernetes 允许对资源进行多种操作，可以通过 \u0026ndash;help 查看详细的操作命令： 1 kubectl --help 经常使用的操作如下所示： ① 基本命令： 命令 翻译 命令作用 create 创建 创建一个资源 edit 编辑 编辑一个资源 get 获取 获取一个资源 patch 更新 更新一个资源 delete 删除 删除一个资源 explain 解释 展示资源文档 ② 运行和调试： 命令 翻译 命令作用 run 运行 在集群中运行一个指定的镜像 expose 暴露 暴露资源为 Service describe 描述 显示资源内部信息 logs 日志 输出容器在 Pod 中的日志 attach 缠绕 进入运行中的容器 exec 执行 执行容器中的一个命令 cp 复制 在 Pod 内外复制文件 rollout 首次展示 管理资源的发布 scale 规模 扩（缩）容 Pod 的数量 autoscale 自动调整 自动调整 Pod 的数量 ③ 高级命令： 命令 翻译 命令作用 apply 应用 通过文件对资源进行配置 label 标签 更新资源上的标签 ④ 其他命令： 命令 翻译 命令作用 cluster-info 集群信息 显示集群信息 version 版本 显示当前 Client 和 Server 的版本 资源类型（type） Kubernetes 中所有的内容都抽象为资源，可以通过下面的命令进行查看： 1 kubectl api-resources 经常使用的资源如下所示： ① 集群级别资源： 资源名称 缩写 资源作用 nodes no 集群组成部分 namespaces ns 隔离 Pod ② Pod资源： 资源名称 缩写 资源作用 Pods po 装载容器 ③ Pod资源控制器： 资源名称 缩写 资源作用 replicationcontrollers rc 控制 Pod 资源 replicasets rs 控制 Pod 资源 deployments deploy 控制 Pod 资源 daemonsets ds 控制 Pod 资源 jobs 控制 Pod 资源 cronjobs cj 控制 Pod 资源 horizontalpodautoscalers hpa 控制 Pod 资源 statefulsets sts 控制 Pod 资源 ④ 服务发现资源： 资源名称 缩写 资源作用 services svc 统一 Pod 对外接口 ingress ing 统一 Pod 对外接口 ⑤ 存储资源： 资源名称 缩写 资源作用 volumeattachments 存储 persistentvolumes pv 存储 persistentvolumeclaims pvc 存储 ⑥ 配置资源： 资源名称 缩写 资源作用 configmaps cm 配置 secrets 配置 示例：查询命名空间 1 kubectl get ns 示例：创建命名空间 1 kubectl create ns dev 示例：删除命名空间 1 kubectl delete ns dev 命令式对象配置 命令式对象配置就是通过命令配置和配置文件去操作 Kubernetes 的资源。 命令式对象配置的方式操作资源，可以简单的认为：命令 + yaml 配置文件（里面是命令需要的各种参数）。 示例： ① 创建一个 nginxpod.yaml 文件，内容如下（第五行的三横杠 \u0026mdash; 是yaml的结束标志，后面的可以理解为另一个yaml了）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: v1 kind: Pod metadata: name: nginxpod namespace: dev spec: containers: - name: nginx-containers image: nginx:1.17.1 ② 执行 create 命令，创建资源： 1 kubectl create -f nginxpod.yaml ③ 执行 get 命令，查看资源： 1 kubectl get -f nginxpod.yaml ④ 执行 delete 命令，删除资源： 1 kubectl delete -f nginxpod.yaml 声明式对象配置 声明式对象配置：通过 apply 命令和配置文件去操作 Kubernetes 的资源。\n声明式对象配置和命令式对象配置类似，只不过它只有一个 apply 命令。\napply 命令相当于 create 命令和 patch 命令。\n示例：\n① 创建一个 nginxpod.yaml 文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: v1 kind: Pod metadata: name: nginxpod namespace: dev spec: containers: - name: nginx-containers image: nginx:1.17.1 ② 执行 apply 命令： 1 kubectl apply -f nginxpod.yaml 总结 创建和更新资源使用声明式对象配置：kubectl apply -f xxx.yaml。 删除资源使用命令式对象配置：kubectl delete -f xxx.yaml。 查询资源使用命令式对象管理：kubectl get(describe) 资源名称。 故障排除（必须记住） 显示资源列表 命令： 1 kubectl get 资源类型 示例：获取类型为 Deployment 的资源列表 1 kubectl get deployment 示例：获取类型为 Pod 的资源列表 1 kubectl get pod 示例：获取类型为 Node 的资源列表 1 kubectl get node 示例：显示所有名称空间下的 Deployment 1 kubectl get deployment -A 1 kubectl get deployment --all-namespaces 示例：查看 kube-system 名称空间下的 Deployment 1 kubectl get deployment -n kube-system 示例：查看在名称空间下的资源对象 1 kubectl api-resources --namespaced=true 示例：查询不在名称空间下的资源对象（理解：就是受 Kubernetes 集群统一调度，而不受到具体名称空间的约束） 1 kubectl api-resources --namespaced=false 显示有关资源的详细信息 命令： 1 kubectl describe 资源类型 资源名称 示例：查询名称为 nginx-pod 的 Pod 的信息 1 kubectl describe pod nginxpod -n dev 示例：显示名称为 nginx 的 Deployment 的信息 1 kubectl describe deployment nginx 查询 Pod 中的容器的打印日志 命令：类似于 Docker 的 docker logs -f xxx 1 kubectl logs -f Pod名称 示例：查询名称为 nginxpod 的 Pod 日志 1 kubectl logs -f nginxpod -n dev 在 Pod 中的容器环境内执行命令 命令：类似于 Docker 的 docker exec -it xxx /bin/bash 1 kubectl exec -it xxx -- /bin/bash 示例：在名称为 nginx-pod 的容器中执行命令 1 kubectl exec -it nginx-pod -- /bin/bash 第三章：实战入门 Namespace Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离。 默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的\u0026quot;组\u0026quot;，以方便不同的组的资源进行隔离使用和管理。 可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。 namespace资源隔离、网络不隔离，如：配置文件不可以跨namespace访问，但是网络访问可以跨名称空间访问。 kubernetes在集群启动之后，会默认创建几个namespace\n1 2 3 4 5 6 [root@master ~]# kubectl get namespace NAME STATUS AGE default Active 45h # 所有未指定Namespace的对象都会被分配在default命名空间 kube-node-lease Active 45h # 集群节点之间的心跳维护，v1.13开始引入 kube-public Active 45h # 此命名空间下的资源可以被所有人访问（包括未认证用户） kube-system Active 45h # 所有由Kubernetes系统创建的资源都处于这个命名空间 下面来看namespace资源的具体操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # 1 查看所有的ns 命令：kubectl get ns [root@master ~]# kubectl get ns NAME STATUS AGE default Active 45h kube-node-lease Active 45h kube-public Active 45h kube-system Active 45h # 2 查看指定的ns 命令：kubectl get ns ns名称 [root@master ~]# kubectl get ns default NAME STATUS AGE default Active 45h # 3 指定输出格式 命令：kubectl get ns ns名称 -o 格式参数 # kubernetes支持的格式有很多，比较常见的是wide、json、yaml [root@master ~]# kubectl get ns default -o yaml apiVersion: v1 kind: Namespace metadata: creationTimestamp: \u0026#34;2020-04-05T04:44:16Z\u0026#34; name: default resourceVersion: \u0026#34;151\u0026#34; selfLink: /api/v1/namespaces/default uid: 7405f73a-e486-43d4-9db6-145f1409f090 spec: finalizers: - kubernetes status: phase: Active # 4 查看ns详情 命令：kubectl describe ns ns名称 [root@master ~]# kubectl describe ns default Name: default Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Status: Active # Active 命名空间正在使用中 Terminating 正在删除命名空间 # ResourceQuota 针对namespace做的资源限制 # LimitRange针对namespace中的每个组件做的资源限制 No resource quota. No LimitRange resource. 创建namespace\n1 2 3 # 创建namespace [root@master ~]# kubectl create ns dev namespace/dev created 删除\n1 2 3 # 删除namespace [root@master ~]# kubectl delete ns dev namespace \u0026#34;dev\u0026#34; deleted 配置方式\n首先准备一个yaml文件：ns-dev.yaml\n1 2 3 4 apiVersion: v1 kind: Namespace metadata: name: dev 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f ns-dev.yaml\n删除：kubectl delete -f ns-dev.yaml\nPod Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。\nPod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。\nkubernetes在集群启动之后，集群中的各个组件也都是以Pod方式运行的。可以通过下面命令查看：\n创建并运行\nkubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的\n高版本的kubernetes创建的不是控制器，就是pod本身，可以通过kubectl create deployment 这种方式创建才有控制器，run是自由式创建，是没有控制器的，可以试试两种方式去创建nginx，用create deployment创建的nginx，用delete pod方法删了pod后会自动重启\n1 2 3 4 5 6 # 命令格式： kubectl run (pod控制器名称) [参数] # --image 指定Pod的镜像 # --port 指定端口 # --namespace 指定namespace [root@master ~]# kubectl run nginx --image=nginx:1.17.1 --port=80 --namespace dev pod/nginx created 1 2 3 kubectl create deployment nginx --image=nginx:1.17.1 --port=80 --namespace dev #页面显示deployment.apps/nginx created 查看pod信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # 查看Pod基本信息 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx-5ff7956ff6-fg2db 1/1 Running 0 43s # 查看Pod的详细信息 [root@master ~]# kubectl describe pod nginx-5ff7956ff6-fg2db -n dev Name: nginx-5ff7956ff6-fg2db Namespace: dev Priority: 0 Node: node1/192.168.109.101 Start Time: Wed, 08 Apr 2020 09:29:24 +0800 Labels: pod-template-hash=5ff7956ff6 run=nginx Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.244.1.23 IPs: IP: 10.244.1.23 Controlled By: ReplicaSet/nginx-5ff7956ff6 Containers: nginx: Container ID: docker://4c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c Image: nginx:1.17.1 Image ID: docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 Port: 80/TCP Host Port: 0/TCP State: Running Started: Wed, 08 Apr 2020 09:30:01 +0800 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-hwvvw (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-hwvvw: Type: Secret (a volume populated by a Secret) SecretName: default-token-hwvvw Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned dev/nginx-5ff7956ff6-fg2db to node1 Normal Pulling 4m11s kubelet, node1 Pulling image \u0026#34;nginx:1.17.1\u0026#34; Normal Pulled 3m36s kubelet, node1 Successfully pulled image \u0026#34;nginx:1.17.1\u0026#34; Normal Created 3m36s kubelet, node1 Created container nginx Normal Started 3m36s kubelet, node1 Started container nginx 访问Pod\n1.21此版本下 pod不能直接在宿主机访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 获取podIP [root@master ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ... nginx-5ff7956ff6-fg2db 1/1 Running 0 190s 10.244.1.23 node1 ... #访问POD [root@master ~]# curl http://10.244.1.23:80 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 删除指定Pod\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 删除指定Pod [root@master ~]# kubectl delete pod nginx-5ff7956ff6-fg2db -n dev pod \u0026#34;nginx-5ff7956ff6-fg2db\u0026#34; deleted # 此时，显示删除Pod成功，但是再查询，发现又新产生了一个 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx-5ff7956ff6-jj4ng 1/1 Running 0 21s # 这是因为当前Pod是由Pod控制器创建的，控制器会监控Pod状况，一旦发现Pod死亡，会立即重建 # 此时要想删除Pod，必须删除Pod控制器 # 先来查询一下当前namespace下的Pod控制器 [root@master ~]# kubectl get deploy -n dev NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 9m7s # 接下来，删除此PodPod控制器 [root@master ~]# kubectl delete deploy nginx -n dev deployment.apps \u0026#34;nginx\u0026#34; deleted # 稍等片刻，再查询Pod，发现Pod被删除了 [root@master ~]# kubectl get pods -n dev No resources found in dev namespace. 配置操作\n创建一个pod-nginx.yaml，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: v1 kind: Pod metadata: name: nginx namespace: dev spec: containers: - image: nginx:1.17.1 name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f pod-nginx.yaml\n删除：kubectl delete -f pod-nginx.yaml\nLabel Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。\nLabel的特点：\n一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等 一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去 Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除 可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。\n一些常用的Label 示例如下：\n版本标签：\u0026ldquo;version\u0026rdquo;:\u0026ldquo;release\u0026rdquo;, \u0026ldquo;version\u0026rdquo;:\u0026ldquo;stable\u0026rdquo;\u0026hellip;\u0026hellip; 环境标签：\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;dev\u0026rdquo;，\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;test\u0026rdquo;，\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;pro\u0026rdquo; 架构标签：\u0026ldquo;tier\u0026rdquo;:\u0026ldquo;frontend\u0026rdquo;，\u0026ldquo;tier\u0026rdquo;:\u0026ldquo;backend\u0026rdquo; 标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：\nLabel用于给某个资源对象定义标识\nLabel Selector用于查询和筛选拥有某些标签的资源对象\n当前有两种Label Selector：\n基于等式的Label Selector name = slave: 选择所有包含Label中key=\u0026ldquo;name\u0026quot;且value=\u0026ldquo;slave\u0026quot;的对象env != production: 选择所有包括Label中的key=\u0026ldquo;env\u0026quot;且value不等于\u0026quot;production\u0026quot;的对象\n基于集合的Label Selector name in (master, slave): 选择所有包含Label中的key=\u0026ldquo;name\u0026quot;且value=\u0026ldquo;master\u0026quot;或\u0026quot;slave\u0026quot;的对象name not in (frontend): 选择所有包含Label中的key=\u0026ldquo;name\u0026quot;且value不等于\u0026quot;frontend\u0026quot;的对象\n标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号\u0026rdquo;,\u0026ldquo;进行分隔即可。例如：\nname=slave，env!=production\nname not in (frontend)，env!=production\n命令方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 为pod资源打标签 [root@master ~]# kubectl label pod nginx-pod version=1.0 -n dev pod/nginx-pod labeled # 为pod资源更新标签 [root@master ~]# kubectl label pod nginx-pod version=2.0 -n dev --overwrite pod/nginx-pod labeled # 查看标签 [root@master ~]# kubectl get pod nginx-pod -n dev --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-pod 1/1 Running 0 10m version=2.0 # 筛选标签 [root@master ~]# kubectl get pod -n dev -l version=2.0 --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-pod 1/1 Running 0 17m version=2.0 [root@master ~]# kubectl get pod -n dev -l version!=2.0 --show-labels No resources found in dev namespace. #删除标签 [root@master ~]# kubectl label pod nginx-pod version- -n dev pod/nginx-pod labeled 配置方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 apiVersion: v1 kind: Pod metadata: name: nginx namespace: dev labels: version: \u0026#34;3.0\u0026#34; env: \u0026#34;test\u0026#34; spec: containers: - image: nginx:1.17.1 name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP 然后就可以执行对应的更新命令了：kubectl apply -f pod-nginx.yaml\nDeployment 在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。\n在kubernetes中Pod控制器的种类有很多，本章节只介绍一种：Deployment。\nDeployment 控制器并不直接管理 Pod，而是通过管理 ReplicaSet 来间接管理 Pod ，即：Deployment 管理 ReplicaSet，ReplicaSet 管理 Pod 。所以 Deployment 的功能比 ReplicaSet 强大。\n命令操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 [root@master ~]# kubectl create deployment nginx --image=nginx --port=80 --replicas=3 -n dev deployment.apps/nginx created # 查看创建的deploy和Pod [root@master ~]# kubectl get deploy,pods -n dev NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx 3/3 3 3 73s NAME READY STATUS RESTARTS AGE pod/nginx-7848d4b86f-dnvkv 1/1 Running 0 73s pod/nginx-7848d4b86f-fkr8j 1/1 Running 0 73s pod/nginx-7848d4b86f-pff2q 1/1 Running 0 73s # UP-TO-DATE：成功升级的副本数量 # AVAILABLE：可用副本的数量 [root@master ~]# kubectl get deploy -n dev -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 2m51s nginx nginx:1.17.1 run=nginx # 查看deployment的详细信息 [root@master ~]# kubectl describe deploy nginx -n dev Name: nginx Namespace: dev CreationTimestamp: Tue, 20 Feb 2024 23:31:41 +0800 Labels: app=nginx Annotations: deployment.kubernetes.io/revision: 1 Selector: app=nginx Replicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=nginx Containers: nginx: Image: nginx Port: 80/TCP Host Port: 0/TCP Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: nginx-7848d4b86f (3/3 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 3m13s deployment-controller Scaled up replica set nginx-7848d4b86f to 3 # 删除 [root@master ~]# kubectl delete deploy nginx -n dev deployment.apps \u0026#34;nginx\u0026#34; deleted 配置操作\n创建一个deploy-nginx.yaml，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 apiVersion: apps/v1 # 版本号 kind: Deployment # 类型 metadata: # 元数据 name: nginx # rs名称 namespace: dev # 所属命名空间 labels: #标签 controller: deploy spec: # 详情描述 replicas: 3 # 副本数量 revisionHistoryLimit: 3 # 保留历史版本，默认为10 paused: false # 暂停部署，默认是false progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600 strategy: # 策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: # 滚动更新 maxSurge: 30% # 最大额外可以存在的副本数，可以为百分比，也可以为整数 maxUnavailable: 30% # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f deploy-nginx.yaml\n删除：kubectl delete -f deploy-nginx.yaml\nService 通过上节课的学习，已经能够利用Deployment来创建一组Pod来提供具有高可用性的服务。\n虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：\nPod IP 会随着Pod的重建产生变化 Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问 这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。\nService可以看作是一组同类Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。\n操作一：创建集群内部可访问的Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 暴露Service [root@master ~]# kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev service/svc-nginx1 exposed # 查看service [root@master ~]# kubectl get svc svc-nginx1 -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR svc-nginx1 ClusterIP 10.96.57.211 \u0026lt;none\u0026gt; 80/TCP 50s app=nginx-pod # 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的 # 可以通过这个IP访问当前service对应的POD [root@master ~]# curl 10.109.179.231:80 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; ....... \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 操作二：创建集群外部也可访问的Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问 # 如果需要创建外部也可以访问的Service，需要修改type为NodePort [root@master ~]# kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev service/svc-nginx2 exposed # 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928/TC） [root@master ~]# kubectl get svc svc-nginx-2 -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR svc-nginx2 NodePort 10.100.94.0 \u0026lt;none\u0026gt; 80:31928/TCP 9s run=nginx # 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了 # 例如在的电脑主机上通过浏览器访问下面的地址 http://192.168.109.100:31928/ 删除Service\n1 2 [root@master ~]# kubectl delete svc svc-nginx1 -n dev service \u0026#34;svc-nginx1\u0026#34; deleted 配置方式\n创建一个svc-nginx.yaml，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: v1 kind: Service metadata: name: svc-nginx namespace: dev spec: clusterIP: 10.109.179.231 ports: - port: 80 protocol: TCP targetPort: 80 selector: run: nginx type: ClusterIP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f svc-nginx.yaml\n删除：kubectl delete -f svc-nginx.yaml\n小结\n至此，已经掌握了Namespace、Pod、Deployment、Service资源的基本操作，有了这些操作，就可以在kubernetes集群中实现一个服务的简单部署和访问了，但是如果想要更好的使用kubernetes，就需要深入学习这几种资源的细节和原理。\n后续k8s详解可以看：\nhttps://www.yuque.com/fairy-era/yg511q/lmy7gc#9d0a1c8b\n","date":"2024-03-12T14:30:05+08:00","image":"https://xxl999227.github.io/archives/kubernetes3kubernetesv1.21%E6%A6%82%E5%BF%B5/img/image.png","permalink":"https://xxl999227.github.io/archives/kubernetes3kubernetesv1.21%E6%A6%82%E5%BF%B5/","title":"【kubernetes】3、Kubernetes（v1.21）概念"},{"content":"前置知识点 目前生产部署Kubernetes 集群主要有两种方式：\nkubeadm\nKubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。\n官方地址：https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/\n二进制包\n从github 下载发行版的二进制包，手动部署每个组件，组成Kubernetes 集群。\nKubeadm 降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes 集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。\nkubeadm 部署方式介绍 kubeadm 是官方社区推出的一个用于快速部署kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes 集群的部署：\n创建一个Master 节点kubeadm init 将Node 节点加入到当前集群中$ kubeadm join \u0026lt;Master 节点的IP 和端口\u0026gt; 安装要求 在开始之前，部署Kubernetes 集群机器需要满足以下几个条件：\n一台或多台机器，操作系统CentOS7.x-86_x64，版本需要大于7.5，否则会出现问题，例如节点加入不到集群 硬件配置：2GB 或更多RAM，2 个CPU 或更多CPU，硬盘30GB 或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁止swap 分区 2.4 最终目标 在所有节点上安装Docker 和kubeadm 部署Kubernetes Master 部署容器网络插件 部署Kubernetes Node，将节点加入Kubernetes 集群中 部署Dashboard Web 页面，可视化查看Kubernetes 资源 准备环境 角色 IP地址 组件 master 192.168.79.100 docker，kubectl，kubeadm，kubelet node1 192.168.79.101 docker，kubectl，kubeadm，kubelet node2 192.168.79.102 docker，kubectl，kubeadm，kubelet 虚拟机准备和网络设置参考：[6-环境搭建\u0026ndash;主机安装_哔哩哔哩_bilibili]\n系统初始化 1 2 #先查看版本，必须要大于centos7.5 cat /etc/redhat-release 设置 Host 文件的相互解析（所有节点都要操作） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 cat \u0026lt;\u0026lt;EOF\u0026gt;\u0026gt; /etc/hosts 192.168.79.100 master 192.168.79.101 node1 192.168.79.102 node2 EOF #执行完后可以查看一下 vi /etc/hosts # 出现如下提示则成功 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.79.100 master 192.168.79.101 node1 192.168.79.102 node2 然后在任意一台机器上ping master或者ping node1或者ping node2都能通\n禁用 Iptables 和firewalld服务（所有节点都要操作） k8和docker运行过程中会产生大量Iptables规则，避免与系统规则混淆，先禁用\n1 2 3 4 5 6 7 #禁用 systemctl stop firewalld #关闭开机自启动 systemctl disable firewalld #本系统其实没有iptables systemctl stop iptables systemctl disable iptables 禁用 SELINUX 和swap分区（所有节点都要操作） linux的一个安全服务，如果不关闭容易遇到奇葩问题\n1 2 #setenforce 0只能暂时关闭，需要将/etc/selinux/config中的SELINUX选项改为disabled setenforce 0 \u0026amp;\u0026amp; sed -i \u0026#39;s/^SELINUX=.*/SELINUX=disabled/\u0026#39; /etc/selinux/config swap分区指的是虚拟内存分区,它的作用是在物理内存使用完之后,将磁盘空间虚拟成内存来使用\n启用swap设备会对系统的性能产生非常负面的影响,因此kubernetes要求每个节点都要禁用swap设备\n但是如果因为某些原因确实不能关闭swap分区,就需要在集群安装过程中通过明确的参数进行配置说明\n1 2 #swapoff -a只能暂时关闭，需要注释掉/etc/fstab中最后一行 swapoff -a \u0026amp;\u0026amp; sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab 修改linux内核参数（所有节点都要操作） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #加载网桥过滤模块 modprobe br_netfilter #在当前路径下生成kubernetes.conf文件，编辑内核参数，添加网桥过滤和地址转发功能， cat \u0026lt;\u0026lt;EOF\u0026gt; kubernetes.conf net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 EOF #拷贝文件到指定目录 cp kubernetes.conf /etc/sysctl.d/kubernetes.conf #重新加载配置 sysctl -p /etc/sysctl.d/kubernetes.conf 时间同步（所有节点都要操作） Kubernetes 要求集群中的节点时间必须精确一致，所以在每个节点上添加时间同步，这里直接用chronyd服务从网络同步时间 1 2 3 4 5 6 7 8 9 #启动服务 systemctl start chronyd #设置开机自启 systemctl enable chronyd #验证 date 配置ipvs（所有节点都要操作） 在 Kubernetes 中 service 有两种代理模型，一种是基于 iptables ，另一种是基于 ipvs 的。ipvs 的性能要高于 iptables 的，但是如果要使用它，需要手动载入 ipvs 模块。\n●在三台机器安装 ipset 和 ipvsadm ：\n1 2 #安装 ipset 和 ipvsadm yum -y install ipset ipvsadm 1 2 3 4 5 6 7 8 9 10 11 #生成脚本文件 cat \u0026lt;\u0026lt;EOF\u0026gt; /etc/sysconfig/modules/ipvs.modules #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF #授权脚本文件，执行，然后查看结果 chmod 755 /etc/sysconfig/modules/ipvs.modules \u0026amp;\u0026amp; bash /etc/sysconfig/modules/ipvs.modules \u0026amp;\u0026amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4 重启机器 1 2 3 4 5 6 7 reboot #重启后查看配置是否生效，出现disable则ok getenforce #swap分区相关都是0则ok free -m 安装 Docker 版本20.10.8（所有节点都要操作） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #先配置阿里云的镜像源 yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #查看存储库中 Docker 的版本 yum list docker-ce --showduplicates | sort -r #安装指定版本的 Docker（v20.10） yum -y install docker-ce-3:20.10.8-3.el7.x86_64 docker-ce-cli-1:20.10.8-3.el7.x86_64 containerd.io ## 创建 /etc/docker 目录 mkdir /etc/docker cat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://7u7aivp6.mirror.aliyuncs.com\u0026#34;] } EOF # 由于没有启动过docker，所以无需重载配置文件 systemctl daemon-reload #启动docker并设置开机自启动 systemctl start docker \u0026amp;\u0026amp; systemctl enable docker 安装 kubelet kubeadm kubectl 指定版本1.21.10 （所有节点都要操作） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #配置kubernetes镜像源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF #安装kubelet kubeadm kubectl 指定版本 yum install -y kubelet-1.21.10 kubeadm-1.21.10 kubectl-1.21.10 #为了实现 Docker 使用的 cgroup drvier 和 kubelet 使用的 cgroup drver 一致， #建议修改 /etc/sysconfig/kubelet 文件的内容： vim /etc/sysconfig/kubelet # 修改 KUBELET_EXTRA_ARGS=\u0026#34;--cgroup-driver=systemd\u0026#34; KUBE_PROXY_MODE=\u0026#34;ipvs\u0026#34; #设置开机自启，由于没有生成配置文件，集群初始化后自动启动： systemctl enable kubelet 下载 Kubernetes 所需镜像 查看 Kubernetes 安装所需镜像：\n1 kubeadm config images list :::color2 从阿里云拉取所需的七个镜像\n:::\n1 2 3 4 5 6 7 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.21.10 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.21.10 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.21.10 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.21.10 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.4.1 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.13-0 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #查看镜像，这时可以看到镜像的tag不对，需要改为kubernetes的tag，方便后续使用 docker images #给镜像重新打tag docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.21.10 k8s.gcr.io/kube-apiserver:v1.21.10 \u0026amp;\u0026amp; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.21.10 k8s.gcr.io/kube-controller-manager:v1.21.10 \u0026amp;\u0026amp; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.21.10 k8s.gcr.io/kube-scheduler:v1.21.10 \u0026amp;\u0026amp; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.21.10 k8s.gcr.io/kube-proxy:v1.21.10 \u0026amp;\u0026amp; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.4.1 k8s.gcr.io/pause:3.4.1 \u0026amp;\u0026amp; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.13-0 k8s.gcr.io/etcd:3.4.13-0 \u0026amp;\u0026amp; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.0 k8s.gcr.io/coredns:v1.8.0 #可以移除老镜像，也可以不移除 部署Kubernetes Master 初始化主节点（主节点操作） 注意：\napiserver-advertise-address 一定要是master主机的 IP 地址。当然，你可以在任意一台机器上执行下面的命令，它就是主节点 apiserver-advertise-address 、service-cidr 和 pod-network-cidr 不能在同一个网络范围内。 不要使用 172.17.0.1/16 网段范围，因为这是 Docker 默认使用的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #第一个参数为master节点的地址，由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里需要指定阿里云镜像仓库地址 kubeadm init \\ --apiserver-advertise-address=192.168.79.100 \\ --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers \\ --kubernetes-version=v1.21.10 \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=10.244.0.0/16 #安装成功后可以看到 Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.79.100:6443 --token kpoksa.a5dhuqu4ccbap85o \\ --discovery-token-ca-cert-hash sha256:e070c812307c6aaaccb328790001ce5bad043a994106b0949c4930b81e93eadc #然后按照指示执行如下操作 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 如果是 root 用户，还可以执行如下命令 export KUBECONFIG=/etc/kubernetes/admin.conf #此时如果执行kubectl get nodes，可以看到没有任何工作节点 kubectl get nodes 默认的 token 有效期为 24 小时，当过期之后，该 token 就不能用了，这时可以使用如下的命令创建 token ：\n1 kubeadm token create --print-join-command 生成一个永不过期的token\n1 kubeadm token create --ttl 0 --print-join-command 其余工作节点加入主节点 按照上一步的指示，将其余的工作节点加入到主节点\n1 2 kubeadm join 192.168.79.100:6443 --token kpoksa.a5dhuqu4ccbap85o \\ --discovery-token-ca-cert-hash sha256:e070c812307c6aaaccb328790001ce5bad043a994106b0949c4930b81e93eadc 然后再在master节点运行kubectl get nodes可以看到相应的工作节点了\n部署网络 官网 Kubernetes 支持多种网络插件，比如 flannel、calico、canal 等，任选一种即可，本次选择 calico（在 192.168.65.100 节点上执行，网络不行，请点这里 calico.yaml）。 calico 和 k8s 的版本对应 1 2 3 4 5 6 kubectl apply -f https://projectcalico.docs.tigera.io/v3.19/manifests/calico.yaml #网络不好将calico.yaml文件上传到root目录下然后执行 kubectl apply -f /root/calico.yaml #网络这一步的等待时间可能比较久，中间可能会出现部分节点就绪，部分未就绪的情况 然后查看节点状态\n1 2 3 4 5 6 7 8 kubectl get nodes #结果如下 [root@master /]# kubectl get nodes NAME STATUS ROLES AGE VERSION master Ready control-plane,master 27m v1.21.10 node1 Ready \u0026lt;none\u0026gt; 21m v1.21.10 node2 Ready \u0026lt;none\u0026gt; 21m v1.21.10 至此，Kubernetes安装完成 让工作节点也能使用kubectl kubectl的运行是需要进行配置的,它的配置文件是$HOME/.kube,如果想要在node节点运行此命令,需要将\nmaster上的.kube文件复制到node节点上,即在master节点上执行下面操作:\n1 scp -r $HOME/.kube node1:$HOME/ \u0026amp;\u0026amp; scp -r $HOME/.kube node2:$HOME/ 测试kubernetes 集群 部署nginx 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #在控制节点执行安装nginx kubectl create deployment nginx --image=nginx:1.14-alpine #暴露80端口 kubectl expose deployment nginx --port=80 --type=NodePort #查看pod和service kubectl get pod,svc #结果如下 NAME READY STATUS RESTARTS AGE pod/nginx-65c4bffcb6-knqpr 1/1 Running 0 2m20s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 37m service/nginx NodePort 10.96.129.185 \u0026lt;none\u0026gt; 80:32100/TCP 100s 此时可以使用master节点的ip加nginx的端口访问，例如 192.168.79.100:32100\n","date":"2024-02-04T18:19:44+08:00","permalink":"https://xxl999227.github.io/archives/kubernetes2%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BAk8skubeadm%E6%96%B9%E5%BC%8F/","title":"【kubernetes】2、集群环境搭建k8s(kubeadm方式)"},{"content":"应用部署方式演变 在部署应用程序的方式上，主要经历了三个时代：\n传统部署：互联网早期，会直接将应用程序部署在物理机上 优点：简单，不需要其它技术的参与\n缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响\n虚拟化部署：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境 优点：程序环境不会相互产生影响，提供了一定程度的安全性\n缺点：增加了操作系统，浪费了部分资源\n容器化部署：与虚拟化类似，但是共享了操作系统 优点：可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等\n运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦\n容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署\n容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：\n一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器 当并发访问量变大的时候，怎么样做到横向扩展容器数量 这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：\nSwarm：Docker自己的容器编排工具 Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用 Kubernetes：Google开源的的容器编排工具 kubernetes简介 kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器\u0026mdash;-Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。\nkubernetes的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：\n自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整 服务发现：服务可以通过自动发现的形式找到它所依赖的服务 负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本 存储编排：可以根据容器自身的需求自动创建存储卷 kubernetes组件 一个kubernetes集群主要是由控制节点(master)、工作节点(node)构成，每个节点上都会安装不同的组件。\nmaster：集群的控制平面，负责集群的决策 ( 管理 )\nApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制\nScheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上\nControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等\n**Etcd**** \u0026lt;/fo：负责存储集群中各种资源对象的信息\nnode：集群的数据平面，负责为容器提供运行环境 ( 干活 )\nKubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器\nKubeProxy : 负责提供集群内部的服务发现和负载均衡\nDocker : 负责节点上容器的各种操作\n下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：\n首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中 一个nginx服务的安装请求会首先被发送到master节点的apiServer组件 apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer apiServer调用controller-manager去调度Node节点安装nginx服务 kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的podpod是kubernetes的最小操作单元，容器必须跑在pod中至此， 一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理 这样，外界用户就可以访问集群中的nginx服务了\nkubernetes概念 Master：集群控制节点，每个集群需要至少一个master节点负责集群的管控\nNode：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行\nPod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器\nController：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等\nService：pod对外服务的统一入口，下面可以维护者同一类的多个pod\nLabel：标签，用于对pod进行分类，同一类pod会拥有相同的标签\nNameSpace：命名空间，用来隔离pod的运行环境\n","date":"2024-01-28T22:27:57+08:00","image":"https://xxl999227.github.io/archives/kubernetes1kubernetes%E4%BB%8B%E7%BB%8D/img/image.png","permalink":"https://xxl999227.github.io/archives/kubernetes1kubernetes%E4%BB%8B%E7%BB%8D/","title":"【kubernetes】1、kubernetes介绍"},{"content":"好了，我们已经熟悉了Docker的基本用法，接下来可以尝试部署项目了。\n在课前资料中已经提供了一个黑马商城项目给大家，如图：\n项目说明：\nhmall：商城的后端代码 hmall-portal：商城用户端的前端代码 hmall-admin：商城管理端的前端代码 部署的容器及端口说明：\n项目 容器名 端口 备注 hmall hmall 8080 黑马商城后端API入口 hmall-portal nginx 18080 黑马商城用户端入口 hmall-admin 18081 黑马商城管理端入口 mysql mysql 3306 数据库 在正式部署前，我们先删除之前的nginx、dd两个容器：\n1 docker rm -f nginx dd mysql容器中已经准备好了商城的数据，所以就不再删除了。\n部署Java项目 hmall项目是一个maven聚合项目，使用IDEA打开hmall项目，查看项目结构如图：\n我们要部署的就是其中的hm-service，其中的配置文件采用了多环境的方式：\n其中的application-dev.yaml是部署到开发环境的配置，application-local.yaml是本地运行时的配置。\n查看application.yaml，你会发现其中的JDBC地址并未写死，而是读取变量：\n这两个变量在application-dev.yaml和application-local.yaml中并不相同：\n在dev开发环境（也就是Docker部署时）采用了mysql作为地址，刚好是我们的mysql容器名，只要两者在一个网络，就一定能互相访问。\n我们将项目打包：\n结果：\n将hm-service目录下的Dockerfile和hm-service/target目录下的hm-service.jar一起上传到虚拟机的root目录：\n部署项目：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 1.构建项目镜像，不指定tag，则默认为latest docker build -t hmall . # 2.查看镜像 docker images # 结果 REPOSITORY TAG IMAGE ID CREATED SIZE hmall latest 0bb07b2c34b9 43 seconds ago 362MB docker-demo 1.0 49743484da68 24 hours ago 327MB nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB # 3.创建并运行容器，并通过--network将其加入hmall网络，这样才能通过容器名访问mysql docker run -d --name hmall --network hmall -p 8080:8080 hmall 测试，通过浏览器访问：http://你的虚拟机地址:8080/search/list\n部署前端 hmall-portal和hmall-admin是前端代码，需要基于nginx部署。在课前资料中已经给大家提供了nginx的部署目录：\n其中：\nhtml是静态资源目录，我们需要把hmall-portal以及hmall-admin都复制进去 nginx.conf是nginx的配置文件，主要是完成对html下的两个静态资源目录做代理 我们现在要做的就是把整个nginx目录上传到虚拟机的/root目录下：\n然后创建nginx容器并完成两个挂载：\n把/root/nginx/nginx.conf挂载到/etc/nginx/nginx.conf 把/root/nginx/html挂载到/usr/share/nginx/html 由于需要让nginx同时代理hmall-portal和hmall-admin两套前端资源，因此我们需要暴露两个端口：\n18080：对应hmall-portal 18081：对应hmall-admin 命令如下：\n1 2 3 4 5 6 7 8 docker run -d \\ --name nginx \\ -p 18080:18080 \\ -p 18081:18081 \\ -v /root/nginx/html:/usr/share/nginx/html \\ -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf \\ --network hmall \\ nginx 测试，通过浏览器访问：http://你的虚拟机ip:18080\nDockerCompose 大家可以看到，我们部署一个简单的java项目，其中包含3个容器：\nMySQL Nginx Java项目 而稍微复杂的项目，其中还会有各种各样的其它中间件，需要部署的东西远不止3个。如果还像之前那样手动的逐一部署，就太麻烦了。\n而Docker Compose就可以帮助我们实现多个相互关联的Docker容器的快速部署。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器。\n基本语法 docker-compose.yml文件的基本语法可以参考官方文档：\nhttps://docs.docker.com/compose/compose-file/compose-file-v3/\ndocker-compose文件中可以定义多个相互关联的应用容器，每一个应用容器被称为一个服务（service）。由于service就是在定义某个应用的运行时参数，因此与docker run参数非常相似。\n举例来说，用docker run部署MySQL的命令如下：\n1 2 3 4 5 6 7 8 9 10 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ -v ./mysql/data:/var/lib/mysql \\ -v ./mysql/conf:/etc/mysql/conf.d \\ -v ./mysql/init:/docker-entrypoint-initdb.d \\ --network hmall mysql 如果用docker-compose.yml文件来定义，就是这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#34;3.8\u0026#34; services: mysql: image: mysql container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123 volumes: - \u0026#34;./mysql/conf:/etc/mysql/conf.d\u0026#34; - \u0026#34;./mysql/data:/var/lib/mysql\u0026#34; networks: - new networks: new: name: hmall 对比如下：\ndocker run 参数 docker compose 指令 说明 \u0026ndash;name container_name 容器名称 -p ports 端口映射 -e environment 环境变量 -v volumes 数据卷配置 \u0026ndash;network networks 网络 明白了其中的对应关系，相信编写docker-compose文件应该难不倒大家。\n黑马商城部署文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 version: \u0026#34;3.8\u0026#34; services: mysql: image: mysql container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123 volumes: - \u0026#34;./mysql/conf:/etc/mysql/conf.d\u0026#34; - \u0026#34;./mysql/data:/var/lib/mysql\u0026#34; - \u0026#34;./mysql/init:/docker-entrypoint-initdb.d\u0026#34; networks: - hm-net hmall: build: context: . dockerfile: Dockerfile container_name: hmall ports: - \u0026#34;8080:8080\u0026#34; networks: - hm-net depends_on: - mysql nginx: image: nginx container_name: nginx ports: - \u0026#34;18080:18080\u0026#34; - \u0026#34;18081:18081\u0026#34; volumes: - \u0026#34;./nginx/nginx.conf:/etc/nginx/nginx.conf\u0026#34; - \u0026#34;./nginx/html:/usr/share/nginx/html\u0026#34; depends_on: - hmall networks: - hm-net networks: hm-net: name: hmall 基础命令 编写好docker-compose.yml文件，就可以部署项目了。常见的命令：\nhttps://docs.docker.com/compose/reference/\n基本语法如下：\n1 docker compose [OPTIONS] [COMMAND] 其中，OPTIONS和COMMAND都是可选参数，比较常见的有：\n类型 参数或指令 说明 Options -f 指定compose文件的路径和名称 -p 指定project名称。project就是当前compose文件中设置的多个service的集合，是逻辑概念 Commands up 创建并启动所有service容器 down 停止并移除所有容器、网络 ps 列出所有启动的容器 logs 查看指定容器的日志 stop 停止容器 start 启动容器 restart 重启容器 top 查看运行的进程 exec 在指定的运行中容器中执行命令 教学演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 1.进入root目录 cd /root # 2.删除旧容器 docker rm -f $(docker ps -qa) # 3.删除hmall镜像 docker rmi hmall # 4.清空MySQL数据 rm -rf mysql/data # 5.启动所有, -d 参数是后台启动 docker compose up -d # 结果： [+] Building 15.5s (8/8) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 358B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/openjdk:11.0-jre-buster 15.4s =\u0026gt; [1/3] FROM docker.io/library/openjdk:11.0-jre-buster@sha256:3546a17e6fb4ff4fa681c3 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 98B 0.0s =\u0026gt; CACHED [2/3] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo 0.0s =\u0026gt; CACHED [3/3] COPY hm-service.jar /app.jar 0.0s =\u0026gt; exporting to image 0.0s =\u0026gt; =\u0026gt; exporting layers 0.0s =\u0026gt; =\u0026gt; writing image sha256:32eebee16acde22550232f2eb80c69d2ce813ed099640e4cfed2193f71 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/root-hmall 0.0s [+] Running 4/4 ✔ Network hmall Created 0.2s ✔ Container mysql Started 0.5s ✔ Container hmall Started 0.9s ✔ Container nginx Started 1.5s # 6.查看镜像 docker compose images # 结果 CONTAINER REPOSITORY TAG IMAGE ID SIZE hmall root-hmall latest 32eebee16acd 362MB mysql mysql latest 3218b38490ce 516MB nginx nginx latest 605c77e624dd 141MB # 7.查看容器 docker compose ps # 结果 NAME IMAGE COMMAND SERVICE CREATED STATUS PORTS hmall root-hmall \u0026#34;java -jar /app.jar\u0026#34; hmall 54 seconds ago Up 52 seconds 0.0.0.0:8080-\u0026gt;8080/tcp, :::8080-\u0026gt;8080/tcp mysql mysql \u0026#34;docker-entrypoint.s…\u0026#34; mysql 54 seconds ago Up 53 seconds 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060/tcp nginx nginx \u0026#34;/docker-entrypoint.…\u0026#34; nginx 54 seconds ago Up 52 seconds 80/tcp, 0.0.0.0:18080-18081-\u0026gt;18080-18081/tcp, :::18080-18081-\u0026gt;18080-18081/tcp 打开浏览器，访问：http://yourIp:18080\n","date":"2024-01-22T23:50:51+08:00","image":"https://xxl999227.github.io/archives/docker%E7%AF%874%E9%83%A8%E7%BD%B2java%E9%A1%B9%E7%9B%AE/img/image.png","permalink":"https://xxl999227.github.io/archives/docker%E7%AF%874%E9%83%A8%E7%BD%B2java%E9%A1%B9%E7%9B%AE/","title":"【docker篇】4、部署java项目"},{"content":"接下来，我们一起来学习Docker使用的一些基础知识，为将来部署项目打下基础。具体用法可以参考Docker官方文档：\nhttps://docs.docker.com/\n常见命令 首先我们来学习Docker中的常见命令，可以参考官方文档：\nhttps://docs.docker.com/engine/reference/commandline/cli/\n命令介绍 其中，比较常见的命令有：\n命令 说明 文档地址 docker pull 拉取镜像 docker pull docker push 推送镜像到DockerRegistry docker push docker images 查看本地镜像 docker images docker rmi 删除本地镜像 docker rmi docker run 创建并运行容器（不能重复创建） docker run docker stop 停止指定容器 docker stop docker start 启动指定容器 docker start docker restart 重新启动容器 docker restart docker rm 删除指定容器 docs.docker.com docker ps 查看容器 docker ps docker logs 查看容器运行日志 docker logs docker exec 进入容器 docker exec docker save 保存镜像到本地压缩文件 docker save docker load 加载本地压缩文件到镜像 docker load docker inspect 查看容器详细信息 docker inspect 用一副图来表示这些命令的关系：\n补充：\n默认情况下，每次重启虚拟机我们都需要手动启动Docker和Docker中的容器。通过命令可以实现开机自启：\n1 2 3 4 5 # Docker开机自启 systemctl enable docker # Docker容器开机自启 docker update --restart=always [容器名/容器id] 演示 教学环节说明：我们以Nginx为例给大家演示上述命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 第1步，去DockerHub查看nginx镜像仓库及相关信息 # 第2步，拉取Nginx镜像 docker pull nginx # 第3步，查看镜像 docker images # 结果如下： REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB # 第4步，创建并允许Nginx容器 docker run -d --name nginx -p 80:80 nginx # 第5步，查看运行中容器 docker ps # 也可以加格式化方式访问，格式会更加清爽 docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第6步，访问网页，地址：http://虚拟机地址 # 第7步，停止容器 docker stop nginx # 第8步，查看所有容器 docker ps -a --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第9步，再次启动nginx容器 docker start nginx # 第10步，再次查看容器 docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第11步，查看容器详细信息 docker inspect nginx # 第12步，进入容器,查看容器内目录 docker exec -it nginx bash # 或者，可以进入MySQL docker exec -it mysql mysql -uroot -p # 第13步，删除容器 docker rm nginx # 发现无法删除，因为容器运行中，强制删除容器 docker rm -f nginx 命令别名 给常用Docker命令起别名，方便我们访问使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 修改/root/.bashrc文件 vi /root/.bashrc 内容如下： # .bashrc # User specific aliases and functions alias rm=\u0026#39;rm -i\u0026#39; alias cp=\u0026#39;cp -i\u0026#39; alias mv=\u0026#39;mv -i\u0026#39; alias dps=\u0026#39;docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34;\u0026#39; alias dis=\u0026#39;docker images\u0026#39; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi 然后，执行命令使别名生效\n1 source /root/.bashrc 接下来，试试看新的命令吧。\n数据卷 容器是隔离环境，容器内程序的文件、配置、运行时产生的容器都在容器内部，我们要读写容器内的文件非常不方便。大家思考几个问题：\n如果要升级MySQL版本，需要销毁旧容器，那么数据岂不是跟着被销毁了？ MySQL、Nginx容器运行后，如果我要修改其中的某些配置该怎么办？ 我想要让Nginx代理我的静态资源怎么办？ 因此，容器提供程序的运行环境，但是程序运行产生的数据、程序运行依赖的配置都应该与容器****解耦。\n什么是数据卷 数据卷（volume）是一个虚拟目录，是容器内目录与宿主机****目录之间映射的桥梁。\n以Nginx为例，我们知道Nginx中有两个关键的目录：\nhtml：放置一些静态资源 conf：放置配置文件 如果我们要让Nginx代理我们的静态资源，最好是放到html目录；如果我们要修改Nginx的配置，最好是找到conf下的nginx.conf文件。\n但遗憾的是，容器运行的Nginx所有的文件都在容器内部。所以我们必须利用数据卷将两个目录与宿主机目录关联，方便我们操作。如图：\n在上图中：\n我们创建了两个数据卷：conf、html Nginx容器内部的conf目录和html目录分别与两个数据卷关联。 而数据卷conf和html分别指向了宿主机的/var/lib/docker/volumes/conf/_data目录和/var/lib/docker/volumes/html/_data目录 这样以来，容器内的conf和html目录就 与宿主机的conf和html目录关联起来，我们称为挂载。此时，我们操作宿主机的/var/lib/docker/volumes/html/_data就是在操作容器内的/usr/share/nginx/html/_data目录。只要我们将静态资源放入宿主机对应目录，就可以被Nginx代理了。\n小提示：\n/var/lib/docker/volumes这个目录就是默认的存放所有容器数据卷的目录，其下再根据数据卷名称创建新目录，格式为/数据卷名/_data。\n为什么不让容器目录直接指向宿主机目录呢？\n因为直接指向宿主机目录就与宿主机强耦合了，如果切换了环境，宿主机目录就可能发生改变了。由于容器一旦创建，目录挂载就无法修改，这样容器就无法正常工作了。 但是容器指向数据卷，一个逻辑名称，而数据卷再指向宿主机目录，就不存在强耦合。如果宿主机目录发生改变，只要改变数据卷与宿主机目录之间的映射关系即可。 不过，我们通过由于数据卷目录比较深，不好寻找，通常我们也允许让容器直接与宿主机目录挂载而不使用数据卷，具体参考2.2.3小节。\n数据卷命令 数据卷的相关命令有：\n命令 说明 文档地址 docker volume create 创建数据卷 docker volume create docker volume ls 查看所有数据卷 docs.docker.com docker volume rm 删除指定数据卷 docs.docker.com docker volume inspect 查看某个数据卷的详情 docs.docker.com docker volume prune 清除数据卷 docker volume prune 注意：容器与数据卷的挂载要在创建容器时配置，对于创建好的容器，是不能设置数据卷的。而且创建容器的过程中，数据卷会自动创建。\n教学演示环节：演示一下nginx的html目录挂载\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 1.首先创建容器并指定数据卷，注意通过 -v 参数来指定数据卷 docker run -d --name nginx -p 80:80 -v html:/usr/share/nginx/html nginx # 2.然后查看数据卷 docker volume ls # 结果 DRIVER VOLUME NAME local 29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f local html # 3.查看数据卷详情 docker volume inspect html # 结果 [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2024-05-17T19:57:08+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: null, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/html/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;html\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] # 4.查看/var/lib/docker/volumes/html/_data目录 ll /var/lib/docker/volumes/html/_data # 可以看到与nginx的html目录内容一样，结果如下： 总用量 8 -rw-r--r--. 1 root root 497 12月 28 2021 50x.html -rw-r--r--. 1 root root 615 12月 28 2021 index.html # 5.进入该目录，并随意修改index.html内容 cd /var/lib/docker/volumes/html/_data vi index.html # 6.打开页面，查看效果 # 7.进入容器内部，查看/usr/share/nginx/html目录内的文件是否变化 docker exec -it nginx bash 教学演示环节：演示一下MySQL的匿名数据卷\n1 2 3 # 1.查看MySQL容器详细信息 docker inspect mysql # 关注其中.Config.Volumes部分和.Mounts部分 我们关注两部分内容，第一是.Config.Volumes部分：\n1 2 3 4 5 6 7 8 9 { \u0026#34;Config\u0026#34;: { // ... 略 \u0026#34;Volumes\u0026#34;: { \u0026#34;/var/lib/mysql\u0026#34;: {} } // ... 略 } } 可以发现这个容器声明了一个本地目录，需要挂载数据卷，但是数据卷未定义。这就是匿名卷。\n然后，我们再看结果中的.Mounts部分：\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/var/lib/mysql\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, } ] } 可以发现，其中有几个关键属性：\nName：数据卷名称。由于定义容器未设置容器名，这里的就是匿名卷自动生成的名字，一串hash值。 Source：宿主机目录 Destination : 容器内的目录 上述配置是将容器内的/var/lib/mysql这个目录，与数据卷29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f挂载。于是在宿主机中就有了/var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data这个目录。这就是匿名数据卷对应的目录，其使用方式与普通数据卷没有差别。\n接下来，可以查看该目录下的MySQL的data文件：\n1 ls -l /var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data 注意：每一个不同的镜像，将来创建容器后内部有哪些目录可以挂载，可以参考DockerHub对应的页面\n挂载本地目录或文件 可以发现，数据卷的目录结构较深，如果我们去操作数据卷目录会不太方便。在很多情况下，我们会直接将容器目录与宿主机指定目录挂载。挂载语法与数据卷类似：\n1 2 3 4 # 挂载本地目录 -v 本地目录:容器内目录 # 挂载本地文件 -v 本地文件:容器内文件 注意：本地目录或文件必须以 / 或 ./开头，如果直接以名字开头，会被识别为数据卷名而非本地目录名。\n例如：\n1 2 -v mysql:/var/lib/mysql # 会被识别为一个数据卷叫mysql，运行时会自动创建这个数据卷 -v ./mysql:/var/lib/mysql # 会被识别为当前目录下的mysql目录，运行时如果不存在会创建目录 教学演示，删除并重新创建mysql容器，并完成本地目录挂载：\n挂载/root/mysql/data到容器内的/var/lib/mysql目录 挂载/root/mysql/init到容器内的/docker-entrypoint-initdb.d目录（初始化的SQL脚本目录） 挂载/root/mysql/conf到容器内的/etc/mysql/conf.d目录（这个是MySQL配置文件目录） 在课前资料中已经准备好了mysql的init目录和conf目录：\n以及对应的初始化SQL脚本和配置文件：\n其中，hm.cnf主要是配置了MySQL的默认编码，改为utf8mb4；而hmall.sql则是后面我们要用到的黑马商城项目的初始化SQL脚本。\n我们直接将整个mysql目录上传至虚拟机的/root目录下：\n接下来，我们演示本地目录挂载：\n其中 / 表示绝对路径，./ 表示相对路径当前目录下\n-v ./mysql/data:/var/lib/mysql \\ 表示将mysql容器的data挂载到宿主机的mysql/data下 -v ./mysql/conf:/etc/mysql/conf.d \\ 表示将mysql容器的配置文件挂载到宿主机的mysql/conf下 -v ./mysql/init:/docker-entrypoint-initdb.d \\ 表示将mysql容器的初始化文件挂载到宿主机的mysql/init下，初始化的sql脚本会在第一次启动容器时自动运行，并且新增的数据也不会随着容器被删除而消失，下一次可以将mysql挂载到同一个地方，数据会仍然存在 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 # 1.删除原来的MySQL容器 docker rm -f mysql # 2.进入root目录 cd ~ # 3.创建并运行新mysql容器，挂载本地目录 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -v ./mysql/data:/var/lib/mysql \\ -v ./mysql/conf:/etc/mysql/conf.d \\ -v ./mysql/init:/docker-entrypoint-initdb.d \\ mysql # 4.查看root目录，可以发现~/mysql/data目录已经自动创建好了 ls -l mysql # 结果： 总用量 4 drwxr-xr-x. 2 root root 20 5月 19 15:11 conf drwxr-xr-x. 7 polkitd root 4096 5月 19 15:11 data drwxr-xr-x. 2 root root 23 5月 19 15:11 init # 查看data目录，会发现里面有大量数据库数据，说明数据库完成了初始化 ls -l data # 5.查看MySQL容器内数据 # 5.1.进入MySQL docker exec -it mysql mysql -uroot -p123456 # 5.2.查看编码表 show variables like \u0026#34;%char%\u0026#34;; # 5.3.结果，发现编码是utf8mb4没有问题 +--------------------------+--------------------------------+ | Variable_name | Value | +--------------------------+--------------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8mb3 | | character_sets_dir | /usr/share/mysql-8.0/charsets/ | +--------------------------+--------------------------------+ # 6.查看数据 # 6.1.查看数据库 show databases; # 结果，hmall是黑马商城数据库 +--------------------+ | Database | +--------------------+ | hmall | | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.00 sec) # 6.2.切换到hmall数据库 use hmall; # 6.3.查看表 show tables; # 结果： +-----------------+ | Tables_in_hmall | +-----------------+ | address | | cart | | item | | order | | order_detail | | order_logistics | | pay_order | | user | +-----------------+ # 6.4.查看address表数据 +----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+ | id | user_id | province | city | town | mobile | street | contact | is_default | notes | +----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+ | 59 | 1 | 北京 | 北京 | 朝阳区 | 13900112222 | 金燕龙办公楼 | 李佳诚 | 0 | NULL | | 60 | 1 | 北京 | 北京 | 朝阳区 | 13700221122 | 修正大厦 | 李佳红 | 0 | NULL | | 61 | 1 | 上海 | 上海 | 浦东新区 | 13301212233 | 航头镇航头路 | 李佳星 | 1 | NULL | | 63 | 1 | 广东 | 佛山 | 永春 | 13301212233 | 永春武馆 | 李晓龙 | 0 | NULL | +----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+ 4 rows in set (0.00 sec) 镜像 前面我们一直在使用别人准备好的镜像，那如果我要部署一个Java项目，把它打包为一个镜像该怎么做呢？\n镜像结构 要想自己构建镜像，必须先了解镜像的结构。\n之前我们说过，镜像之所以能让我们快速跨操作系统部署应用而忽略其运行环境、配置，就是因为镜像中包含了程序运行需要的系统函数库、环境、配置、依赖。\n因此，自定义镜像本质就是依次准备好程序运行的基础环境、依赖、应用本身、运行配置等文件，并且打包而成。\n举个例子，我们要从0部署一个Java应用，大概流程是这样：\n准备一个linux服务（CentOS或者Ubuntu均可） 安装并配置JDK 上传Jar包 运行jar包 那因此，我们打包镜像也是分成这么几步：\n准备Linux运行环境（java项目并不需要完整的操作系统，仅仅是基础运行环境即可） 安装并配置JDK 拷贝jar包 配置启动脚本 上述步骤中的每一次操作其实都是在生产一些文件（系统运行环境、函数库、配置最终都是磁盘文件），所以镜像就是一堆文件的集合。\n但需要注意的是，镜像文件不是随意堆放的，而是按照操作的步骤分层叠加而成，每一层形成的文件都会单独打包并标记一个唯一id，称为Layer（层）。这样，如果我们构建时用到的某些层其他人已经制作过，就可以直接拷贝使用这些层，而不用重复制作。\n例如，第一步中需要的Linux运行环境，通用性就很强，所以Docker官方就制作了这样的只包含Linux运行环境的镜像。我们在制作java镜像时，就无需重复制作，直接使用Docker官方提供的CentOS或Ubuntu镜像作为基础镜像。然后再搭建其它层即可，这样逐层搭建，最终整个Java项目的镜像结构如图所示：\nDockerfile 由于制作镜像的过程中，需要逐层处理和打包，比较复杂，所以Docker就提供了自动打包镜像的功能。我们只需要将打包的过程，每一层要做的事情用固定的语法写下来，交给Docker去执行即可。\n而这种记录镜像结构的文件就称为Dockerfile，其对应的语法可以参考官方文档：\nhttps://docs.docker.com/engine/reference/builder/\n其中的语法比较多，比较常用的有：\n指令 说明 示例 FROM 指定基础镜像 FROM centos:6 ENV 设置环境变量，可在后面指令使用 ENV key value COPY 拷贝本地文件到镜像的指定目录 COPY ./xx.jar /tmp/app.jar RUN 执行Linux的shell命令，一般是安装过程的命令 RUN yum install gcc EXPOSE 指定容器运行时监听的端口，是给镜像使用者看的 EXPOSE 8080 ENTRYPOINT 镜像中应用的启动命令，容器运行时调用 ENTRYPOINT java -jar xx.jar 例如，要基于Ubuntu镜像来构建一个Java应用，其Dockerfile内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 指定基础镜像 FROM ubuntu:16.04 # 配置环境变量，JDK的安装目录、容器内时区 ENV JAVA_DIR=/usr/local ENV TZ=Asia/Shanghai # 拷贝jdk和java项目的包 COPY ./jdk8.tar.gz $JAVA_DIR/ COPY ./docker-demo.jar /tmp/app.jar # 设定时区 RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone # 安装JDK RUN cd $JAVA_DIR \\ \u0026amp;\u0026amp; tar -xf ./jdk8.tar.gz \\ \u0026amp;\u0026amp; mv ./jdk1.8.0_144 ./java8 # 配置环境变量 ENV JAVA_HOME=$JAVA_DIR/java8 ENV PATH=$PATH:$JAVA_HOME/bin # 指定项目监听的端口 EXPOSE 8080 # 入口，java项目的启动命令 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;/app.jar\u0026#34;] 同学们思考一下：以后我们会有很多很多java项目需要打包为镜像，他们都需要Linux系统环境、JDK环境这两层，只有上面的3层不同（因为jar包不同）。如果每次制作java镜像都重复制作前两层镜像，是不是很麻烦。\n所以，就有人提供了基础的系统加JDK环境，我们在此基础上制作java镜像，就可以省去JDK的配置了：\n1 2 3 4 5 6 7 8 9 # 基础镜像 FROM openjdk:11.0-jre-buster # 设定时区 ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone # 拷贝jar包 COPY docker-demo.jar /app.jar # 入口 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;/app.jar\u0026#34;] 是不是简单多了。\n构建镜像 当Dockerfile文件写好以后，就可以利用命令来构建镜像了。\n在课前资料中，我们准备好了一个demo项目及对应的Dockerfile：\n首先，我们将课前资料提供的docker-demo.jar包以及Dockerfile拷贝到虚拟机的/root/demo目录：\n然后，执行命令，构建镜像：\n1 2 3 4 # 进入镜像目录 cd /root/demo # 开始构建 docker build -t docker-demo:1.0 . 命令说明：\ndocker build : 就是构建一个docker镜像 -t docker-demo:1.0 ：-t参数是指定镜像的名称（repository和tag） . : 最后的点是指构建时Dockerfile所在路径，由于我们进入了demo目录，所以指定的是.代表当前目录，也可以直接指定Dockerfile目录： 结果：\n查看镜像列表：\n1 2 # 直接指定Dockerfile目录 docker build -t docker-demo:1.0 /root/demo 1 2 3 4 5 6 7 # 查看镜像列表： docker images # 结果 REPOSITORY TAG IMAGE ID CREATED SIZE docker-demo 1.0 d6ab0b9e64b9 27 minutes ago 327MB nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB 然后尝试运行该镜像：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 1.创建并运行容器 docker run -d --name dd -p 8080:8080 docker-demo:1.0 # 2.查看容器 dps # 结果 CONTAINER ID IMAGE PORTS STATUS NAMES 78a000447b49 docker-demo:1.0 0.0.0.0:8080-\u0026gt;8080/tcp, :::8080-\u0026gt;8080/tcp Up 2 seconds dd f63cfead8502 mysql 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060/tcp Up 2 hours mysql # 3.访问 curl localhost:8080/hello/count # 结果： \u0026lt;h5\u0026gt;欢迎访问黑马商城, 这是您第1次访问\u0026lt;h5\u0026gt; 网络 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #我们可以使用ip a 命令查看网卡 ip a 展示如下： 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:ef:eb:10 brd ff:ff:ff:ff:ff:ff inet 192.168.79.128/24 brd 192.168.79.255 scope global noprefixroute dynamic ens33 valid_lft 1340sec preferred_lft 1340sec inet6 fe80::1f9a:7f21:7dbe:c0d3/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: docker0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:93:59:bb:a6 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:93ff:fe59:bba6/64 scope link valid_lft forever preferred_lft forever 13: veth744375a@if12: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 8a:3c:52:bb:d8:b4 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::883c:52ff:febb:d8b4/64 scope link valid_lft forever preferred_lft forever 21: veth10c9fcd@if20: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 86:ad:81:9b:cd:1e brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::84ad:81ff:fe9b:cd1e/64 scope link valid_lft forever preferred_lft forever 25: vethf09cb49@if24: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether d6:84:b5:ad:c3:85 brd ff:ff:ff:ff:ff:ff link-netnsid 2 inet6 fe80::d484:b5ff:fead:c385/64 scope link valid_lft forever preferred_lft forever 上节课我们创建了一个Java项目的容器，而Java项目往往需要访问其它各种中间件，例如MySQL、Redis等。现在，我们的容器之间能否互相访问呢？我们来测试一下\n首先，我们查看下MySQL容器的详细信息，重点关注其中的网络IP地址：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1.用基本命令，寻找Networks.bridge.IPAddress属性 docker inspect mysql # 也可以使用format过滤结果 docker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{println .IPAddress}}{{end}}\u0026#39; mysql # 得到IP地址如下： 172.17.0.2 # 2.然后通过命令进入dd容器 docker exec -it dd bash # 3.在容器内，通过ping命令测试网络 ping 172.17.0.2 # 结果 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data. 64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.053 ms 64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.059 ms 64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.058 ms 发现可以互联，没有问题。\n但是，容器的网络IP其实是一个虚拟的IP，其值并不固定与某一个容器绑定，如果我们在开发时写死某个IP，而在部署时很可能MySQL容器的IP会发生变化，连接会失败。\n所以，我们必须借助于docker的网络功能来解决这个问题，官方文档：\nhttps://docs.docker.com/engine/reference/commandline/network/\n加入自定义网络的容器才可以通过容器名互相访问，默认网络没有此功能\n常见命令有：\n命令 说明 文档地址 docker network create 创建一个网络 docker network create docker network ls 查看所有网络 docs.docker.com docker network rm 删除指定网络 docs.docker.com docker network prune 清除未使用的网络 docs.docker.com docker network connect 使指定容器连接加入某网络 docs.docker.com docker network disconnect 使指定容器连接离开某网络 docker network disconnect docker network inspect 查看网络详细信息 docker network inspect 教学演示：自定义网络\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # 1.首先通过命令创建一个网络 docker network create hmall # 2.然后查看网络 docker network ls # 结果： NETWORK ID NAME DRIVER SCOPE 639bc44d0a87 bridge bridge local 403f16ec62a2 hmall bridge local 0dc0f72a0fbb host host local cd8d3e8df47b none null local # 其中，除了hmall以外，其它都是默认的网络 # 3.让dd和mysql都加入该网络，注意，在加入网络时可以通过--alias给容器起别名 # 这样该网络内的其它容器可以用别名互相访问！ # 3.1.mysql容器，指定别名为db，另外每一个容器都有一个别名是容器名 docker network connect hmall mysql --alias db # 3.2.dd容器，也就是我们的java项目 docker network connect hmall dd # 4.进入dd容器，尝试利用别名访问db # 4.1.进入容器 docker exec -it dd bash # 4.2.用db别名访问 ping db # 结果 PING db (172.18.0.2) 56(84) bytes of data. 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.070 ms 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.056 ms # 4.3.用容器名访问 ping mysql # 结果： PING mysql (172.18.0.2) 56(84) bytes of data. 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.044 ms 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.054 ms # 也可以在创建容器时指定容器的网络,这样容器只会加入此网络，不会加入默认网络 docker run -d --name dd -p 8080:8080 --network heima docker-demo OK，现在无需记住IP地址也可以实现容器互联了。\n总结：\n在自定义网络中，可以给容器起多个别名，默认的别名是容器名本身 在同一个自定义网络中的容器，可以通过别名互相访问 ","date":"2024-01-18T21:50:56+08:00","image":"https://xxl999227.github.io/archives/docker%E7%AF%873docker%E5%9F%BA%E7%A1%80/img/image.png","permalink":"https://xxl999227.github.io/archives/docker%E7%AF%873docker%E5%9F%BA%E7%A1%80/","title":"【docker篇】3、docker基础"},{"content":"部署MySQL 首先，我们利用Docker来安装一个MySQL软件，大家可以对比一下之前传统的安装方式，看看哪个效率更高一些。\n如果是利用传统方式部署MySQL，大概的步骤有：\n搜索并下载MySQL安装包 上传至Linux环境 编译和配置环境 安装 而使用Docker安装，仅仅需要一步即可，在命令行输入下面的命令（建议采用CV大法）：\n1 2 3 4 5 6 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123456 \\ mysql 运行效果如图：\nMySQL安装完毕！通过任意客户端工具即可连接到MySQL.\n大家可以发现，当我们执行命令后，Docker做的第一件事情，是去自动搜索并下载了MySQL，然后会自动运行MySQL，我们完全不用插手，是不是非常方便。\n而且，这种安装方式你完全不用考虑运行的操作系统环境，它不仅仅在CentOS系统是这样，在Ubuntu系统、macOS系统、甚至是装了WSL的Windows下，都可以使用这条命令来安装MySQL。\n要知道，不同操作系统下其安装包、运行环境是都不相同的！如果是手动安装，必须手动解决安装包不同、环境不同的、配置不同的问题！\n而使用Docker，这些完全不用考虑。就是因为Docker会自动搜索并下载MySQL。注意：这里下载的不是安装包，而是镜像。镜像中不仅包含了MySQL本身，还包含了其运行所需要的环境、配置、系统级函数库。因此它在运行时就有自己独立的环境，就可以跨系统运行，也不需要手动再次配置环境了。这套独立运行的隔离环境我们称为容器。\n说明：\n镜像：英文是image 容器：英文是container 因此，Docker安装软件的过程，就是自动搜索下载镜像，然后创建并运行容器的过程。\nDocker会根据命令中的镜像名称自动搜索并下载镜像，那么问题来了，它是去哪里搜索和下载镜像的呢？这些镜像又是谁制作的呢？\nDocker官方提供了一个专门管理、存储镜像的网站，并对外开放了镜像上传、下载的权利。Docker官方提供了一些基础镜像，然后各大软件公司又在基础镜像基础上，制作了自家软件的镜像，全部都存放在这个网站。这个网站就成了Docker镜像交流的社区：\nhttps://hub.docker.com/\n基本上我们常用的各种软件都能在这个网站上找到，我们甚至可以自己制作镜像上传上去。\n像这种提供存储、管理Docker镜像的服务器，被称为DockerRegistry，可以翻译为镜像仓库。DockerHub网站是官方仓库，阿里云、华为云会提供一些第三方仓库，我们也可以自己搭建私有的镜像仓库。\n官方仓库在国外，下载速度较慢，一般我们都会使用第三方仓库提供的镜像加速功能，提高下载速度。而企业内部的机密项目，往往会采用私有镜像仓库。\n总之，镜像的来源有两种：\n基于官方基础镜像自己制作 直接去DockerRegistry下载 总结一下：\nDocker本身包含一个后台服务，我们可以利用Docker命令告诉Docker服务，帮助我们快速部署指定的应用。Docker服务部署应用时，首先要去搜索并下载应用对应的镜像，然后根据镜像创建并允许容器，应用就部署完成了。\n用一幅图表示如下：\n命令解读 利用Docker快速的安装了MySQL，非常的方便，不过我们执行的命令到底是什么意思呢？\n其实是一行命令，用 \\ 做了换行\n1 2 3 4 5 6 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ mysql 解读：\ndocker run -d ：创建并运行一个容器，-d则是让容器以后台进程运行，基本上都是搭配-d使用 \u0026ndash;name mysql : 给容器起个名字叫mysql，可以叫别的 -p 3306:3306 : 设置端口映射。 容器是隔离环境，外界不可访问。但是可以将宿主机端口****映射容器内到端口，当访问宿主机指定端口时，就是在访问容器内的端口了。 容器内端口往往是由容器内的进程决定，例如MySQL进程默认端口是3306，因此容器内端口一定是3306；而宿主机端口则可以任意指定，一般与容器内保持一致。 格式： -p 宿主机端口:容器内端口，示例中就是将宿主机的3306映射到容器内的3306端口 -e TZ=Asia/Shanghai : 配置容器内进程运行时的一些参数 格式：-e KEY=VALUE，KEY和VALUE都由容器内进程决定 案例中，TZ=Asia/Shanghai是设置时区；MYSQL_ROOT_PASSWORD=123是设置MySQL默认密码 mysql : 设置镜像名称，Docker会根据这个名字搜索并下载镜像 格式：REPOSITORY:TAG，例如mysql:8.0，其中REPOSITORY可以理解为镜像名，TAG是版本号 在未指定TAG的情况下，默认是最新版本，也就是mysql:latest 镜像的名称不是随意的，而是要到DockerRegistry中寻找，镜像运行时的配置也不是随意的，要参考镜像的帮助文档，这些在DockerHub网站或者软件的官方网站中都能找到。\n如果我们要安装其它软件，也可以到DockerRegistry中寻找对应的镜像名称和版本，阅读相关配置即可。\n","date":"2024-01-17T21:33:14+08:00","image":"https://xxl999227.github.io/archives/docker%E7%AF%872%E5%AE%89%E8%A3%85mysql/img/image.png","permalink":"https://xxl999227.github.io/archives/docker%E7%AF%872%E5%AE%89%E8%A3%85mysql/","title":"【docker篇】2、安装Mysql"},{"content":"安装Docker\n本安装教程参考Docker官方文档，地址如下：\nhttps://docs.docker.com/engine/install/centos/\n卸载旧版 首先如果系统中已经存在旧的Docker，则先卸载：\n1 2 3 4 5 6 7 8 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 配置Docker的yum库 首先要安装一个yum工具\n1 yum install -y yum-utils 安装成功后，执行命令，配置Docker的yum源：\n1 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 这里建议阿里云的yum源\n1 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装Docker 最后，执行命令，安装Docker\n1 yum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 启动和校验 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 启动Docker systemctl start docker # 停止Docker systemctl stop docker # 重启 systemctl restart docker # 设置开机自启 systemctl enable docker # 执行docker ps命令，如果不报错，说明安装启动成功 docker ps 配置镜像加速 这里以阿里云镜像加速为例。\n注册阿里云账号 首先访问阿里云网站:\nhttps://www.aliyun.com/\n注册一个账号。\n开通镜像服务 在首页的产品中，找到阿里云的容器镜像服务：\n点击后进入控制台：\n首次可能需要选择立刻开通，然后进入控制台。\n配置镜像加速 找到镜像工具下的镜像****加速器：\n页面向下滚动，即可找到配置的文档说明：\n具体命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建目录 mkdir -p /etc/docker # 复制内容，注意把其中的镜像加速地址改成你自己的 tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://xxxx.mirror.aliyuncs.com\u0026#34;] } EOF # 重新加载配置 systemctl daemon-reload # 重启Docker systemctl restart docker ","date":"2023-12-28T23:10:19+08:00","image":"https://xxl999227.github.io/archives/docker%E7%AF%871%E5%AE%89%E8%A3%85docker/img/image.png","permalink":"https://xxl999227.github.io/archives/docker%E7%AF%871%E5%AE%89%E8%A3%85docker/","title":"【docker篇】1、安装Docker"}]